{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from lxml import etree\n",
    "import re\n",
    "import xlwt\n",
    "import xlrd\n",
    "from xlutils.copy import copy\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import traceback\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用了各种方法，去请求网页数据，都会被网站屏蔽。\n",
    "# 所以这里采用自动化测试点击下一页来获取每页数据\n",
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#沪市、深市、中小板、创业板\n",
    "# browser.get(\"http://data.10jqka.com.cn/financial/yjgg/###\")\n",
    "browser.get(\"http://quote.eastmoney.com/center/gridlist.html#hs_a_board\")\n",
    "#上证50、沪深300、中证500\n",
    "# browser.get('http://data.eastmoney.com/other/index/hs300.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait = WebDriverWait(browser, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workbook = copy(xlrd.open_workbook(\"data/上市公司.xls\"))\n",
    "workbook = xlwt.Workbook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#添加表头\n",
    "def addHeaders(board_name,heads):\n",
    "    # StockCode：股票代码\n",
    "    # StockName：股票简称\n",
    "    # Price：当前股价\n",
    "    '-------每日浮动数据-------'\n",
    "    # PriceLimit：涨跌幅\n",
    "    # QuantityRelativeR：量比\n",
    "    # TurnoverRate：换手率\n",
    "    '-------相对固定数据-------'\n",
    "    # Trade：行业\n",
    "    # PB：市净率\n",
    "    # PE_S：静态市盈率\n",
    "    # PE_D：动态市盈率\n",
    "    # EarningsPerShare：每股收益\n",
    "    # NetProfitDes：净利润描述（包括净利润和增长比率）\n",
    "    # ROE：净资产收益率\n",
    "    # GrossProfitRate：毛利率\n",
    "    # NetAssetValuePerShare：每股净资产\n",
    "    # CapitalStock：股本\n",
    "    # ScaleShareType：类型（大盘股、小盘股）\n",
    "    # FinanceAnalize：财务分析\n",
    "    '-------备用字段-------'\n",
    "    # Proceeds：营业收入\n",
    "    # ProceedsYOY：营业收入-同比增长\n",
    "    # ProceedsQOQ：营业收入-环比增长\n",
    "    # NetProfit：净利润\n",
    "    # NetProfitYOY：净利润-同比增长\n",
    "    # NetProfitQOQ：净利润-环比增长\n",
    "    # MoneyFlowPerShare：每股现金流量\n",
    "    # GrossProfitRate：销售毛利率\n",
    "\n",
    "    sheet = workbook.add_sheet(board_name) \n",
    "    for h in range(len(heads)):\n",
    "        sheet.write(0, h, heads[h]) \n",
    "    return sheet\n",
    "\n",
    "# 获取股票数据\n",
    "# def getStockDataByType(stock_type):\n",
    "#     boards = browser.find_elements_by_class_name(\"J-board-item\")\n",
    "    \n",
    "#     for i,board in enumerate(boards):\n",
    "#         board_name =board.text\n",
    "#         if board_name == stock_type:\n",
    "#             sheet = addHeaders(board_name)\n",
    "#             board.click()\n",
    "#             time.sleep(3)\n",
    "#             print(\"正在获取：\"+board_name+\"...\")\n",
    "#             total_page = int(browser.find_element_by_class_name(\"page_info\").text.split(\"/\")[1])\n",
    "#             for page in range(1,total_page+1):\n",
    "#                 comapnies = browser.find_elements_by_class_name(\"J_showCanvas\")\n",
    "#                 for j,company in enumerate(comapnies):\n",
    "#                     printProgress(\"第\"+str(page)+\"页-\"+\"第\"+str(j)+\"条...\")\n",
    "#                     code = browser.find_element_by_xpath('//*[@id=\"J-ajax-main\"]/table/tbody/tr['+str(j+1)+']/td[2]/a')\n",
    "#                     row = (page-1)*50+1+j\n",
    "#                     sheet.write(row,0,code.text)\n",
    "#                     sheet.write(row,1,company.text)\n",
    "#                     getBaseData(code.text,row,2,sheet)\n",
    "                \n",
    "#                 page_btns = browser.find_elements_by_class_name(\"changePage\")\n",
    "#                 subscript = 0\n",
    "#                 if page != total_page+1:\n",
    "#                     for page_btn in page_btns:\n",
    "#                         if page_btn.text == \"下一页\":\n",
    "#                             subscript = page_btns.index(page_btn)\n",
    "#                     page_btns[subscript].click()\n",
    "#                     time.sleep(3)\n",
    "                    \n",
    "#     browser.close()\n",
    "#     browser.quit()\n",
    "\n",
    "def getStockDataByType(stock_type):\n",
    "    heads = ['StockCode','StockName','Price','PriceLimit','QuantityRelativeR','TurnoverRate',\\\n",
    "    'Trade','PB','PE_S','PE_D','EarningsPerShare','NetProfitDes','ROE','GrossProfitRate','NetAssetValuePerShare','CapitalStock',\\\n",
    "     'ScaleShareType','FinanceAnalize']\n",
    "        \n",
    "    parent = browser.find_element_by_xpath('//*[@id=\"tab\"]/ul')\n",
    "    boards = parent.find_elements_by_xpath('.//*')\n",
    "    \n",
    "    try:\n",
    "        for i,board in enumerate(boards):\n",
    "            board_name =board.text\n",
    "            if board_name == stock_type:\n",
    "                sheet = addHeaders(board_name,heads)\n",
    "                board.click()\n",
    "                time.sleep(3)\n",
    "                print(\"正在获取：\"+board_name+\"...\")\n",
    "                page_parent = browser.find_element_by_class_name('paginate_page')\n",
    "                pages = page_parent.find_elements_by_xpath('.//*')\n",
    "                total_page = int(pages[len(pages) - 1].text)\n",
    "\n",
    "                #统计每页缺失数据的数量\n",
    "                missing_count = 0\n",
    "                for page in range(1,total_page+1):\n",
    "                    for j in range(20):\n",
    "                        printProgress(\"第\"+str(page)+\"页-\"+\"第\"+str(j)+\"条...\")\n",
    "                        company = browser.find_element_by_xpath('//*[@id=\"table_wrapper-table\"]/tbody/tr['+str(j+1)+']/td[3]/a')\n",
    "                        code = browser.find_element_by_xpath('//*[@id=\"table_wrapper-table\"]/tbody/tr['+str(j+1)+']/td[2]/a')\n",
    "                        price = browser.find_element_by_xpath('//*[@id=\"table_wrapper-table\"]/tbody/tr['+str(j+1)+']/td[5]/span')\n",
    "                        pl = browser.find_element_by_xpath('//*[@id=\"table_wrapper-table\"]/tbody/tr['+str(j+1)+']/td[6]/span')\n",
    "                        qrr = browser.find_element_by_xpath('//*[@id=\"table_wrapper-table\"]/tbody/tr['+str(j+1)+']/td[15]')\n",
    "                        tr = browser.find_element_by_xpath('//*[@id=\"table_wrapper-table\"]/tbody/tr['+str(j+1)+']/td[16]')\n",
    "                        \n",
    "                        if price.text != '-':\n",
    "                            row = (page-1)*20 + 1 + j - missing_count\n",
    "                            sheet.write(row,0,code.text)\n",
    "                            sheet.write(row,1,company.text)\n",
    "                            sheet.write(row,2,price.text)\n",
    "                            sheet.write(row,3,pl.text)\n",
    "                            sheet.write(row,4,qrr.text)\n",
    "                            sheet.write(row,5,tr.text)\n",
    "                            getBaseData(code.text,row,6,sheet)\n",
    "                        else:\n",
    "                            missing_count += 1\n",
    "                    page_btn = browser.find_element_by_xpath('//*[@id=\"main-table_paginate\"]/a[2]')\n",
    "                    if page < total_page:\n",
    "                        page_btn.click()\n",
    "                        time.sleep(3)\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "    browser.close()\n",
    "    browser.quit()\n",
    "\n",
    "#获取指数成分股\n",
    "def getIndexStockByType(index_type):\n",
    "    heads = ['StockCode','StockName','Price',\\\n",
    "    'Trade','PB','PE_S','PE_D','EarningsPerShare','NetProfitDes','ROE','GrossProfitRate','NetAssetValuePerShare','CapitalStock',\\\n",
    "     'ScaleShareType','FinanceAnalize']\n",
    "    \n",
    "    parent = browser.find_element_by_id(\"mk_type\")\n",
    "    \n",
    "    boards = parent.find_elements_by_xpath('.//*')\n",
    "    \n",
    "    for i,board in enumerate(boards):\n",
    "        board_name =board.text\n",
    "        if board_name == index_type:\n",
    "            sheet = addHeaders(board_name,heads)\n",
    "            board.click()\n",
    "            time.sleep(3)\n",
    "            print(\"正在获取：\"+board_name+\"...\")\n",
    "            total_page = int(browser.find_element_by_xpath('//*[@id=\"miniPageNav\"]/b[4]/span').text)\n",
    "            for page in range(1,total_page+1):\n",
    "                for j in range(50):\n",
    "                    printProgress(\"第\"+str(page)+\"页-\"+\"第\"+str(j)+\"条...\")\n",
    "                    company = browser.find_element_by_xpath('//*[@id=\"dt_1\"]/tbody/tr['+str(j+1)+']/td[3]/a')\n",
    "                    code = browser.find_element_by_xpath('//*[@id=\"dt_1\"]/tbody/tr['+str(j+1)+']/td[2]/a')\n",
    "                    price = browser.find_element_by_xpath('//*[@id=\"dt_1\"]/tbody/tr['+str(j+1)+']/td[4]/span')\n",
    "                    \n",
    "                    row = (page-1)*50+1+j\n",
    "                    sheet.write(row,0,code.text)\n",
    "                    sheet.write(row,1,company.text)\n",
    "                    sheet.write(row,2,price.text)\n",
    "                    getBaseData(code.text,row,3,sheet)\n",
    "                \n",
    "                page_parent = browser.find_element_by_id(\"PageCont\") \n",
    "                page_btns = page_parent.find_elements_by_xpath('.//*')\n",
    "                subscript = 0\n",
    "                if (len(page_btns) >0)  & (page != total_page+1):\n",
    "                    for page_btn in page_btns:\n",
    "                        if page_btn.text == \"下一页\":\n",
    "                            subscript = page_btns.index(page_btn)\n",
    "                    page_btns[subscript].click()\n",
    "                    time.sleep(3)\n",
    "                    \n",
    "    browser.close()\n",
    "    browser.quit()\n",
    "                \n",
    "def getBaseData(code,row,index,sheet):\n",
    "    try:\n",
    "        #设置用户代理，不然会被网站屏蔽\n",
    "        headers = {\"user-agent\":\"PostmanRuntime/7.13.0\"}\n",
    "        response_1 = requests.get(\"http://basic.10jqka.com.cn/\"+code+\"/company.html\",headers = headers)\n",
    "        response_1.encoding = 'gbk'\n",
    "        e_1 = etree.HTML(response_1.text)\n",
    "        # 获取行业\n",
    "        try:\n",
    "            trade = e_1.xpath('//*[@id=\"detail\"]/div[2]/table/tbody/tr[2]/td[2]/span')[0]\n",
    "            sheet.write(row,index,trade.text)\n",
    "        except IndexError:\n",
    "            try:\n",
    "                trade = e_1.xpath('//*[@id=\"detail\"]/div[3]/table/tbody/tr[2]/td[2]/span')[0]\n",
    "                sheet.write(row,index,trade.text)\n",
    "            except IndexError:\n",
    "                sheet.write(row,index,'未知行业')\n",
    "            \n",
    "#         #上市时间\n",
    "#         ttm = e_1.xpath('//*[@id=\"publish\"]/div[2]/table/tbody/tr[2]/td[1]/span')[0]\n",
    "#         sheet.write(row,index+1,ttm.text)\n",
    "\n",
    "        # 获取市净率\n",
    "        response_2 = requests.get(\"http://basic.10jqka.com.cn/\"+code+\"/\",headers = headers)\n",
    "        response_2.encoding = 'gbk'\n",
    "        e_2 = etree.HTML(response_2.text)\n",
    "        pb = e_2.xpath('//*[@id=\"sjl\"]')[0]\n",
    "        sheet.write(row,index+1,pb.text)\n",
    "        # 获取市盈率\n",
    "        # 静态市盈率\n",
    "        pe_s = e_2.xpath('//*[@id=\"jtsyl\"]')[0]\n",
    "        sheet.write(row,index+2,pe_s.text)\n",
    "        # 动态市盈率\n",
    "        pe_d = e_2.xpath('//*[@id=\"dtsyl\"]')[0]\n",
    "        sheet.write(row,index+3,pe_d.text)\n",
    "        \n",
    "        #每股收益\n",
    "        eps = e_2.xpath('//*[@id=\"profile\"]/div[2]/table[2]/tbody/tr[1]/td[2]/span[2]')[0]\n",
    "        sheet.write(row,index+4,eps.text)\n",
    "        # 净利润\n",
    "        np_des = e_2.xpath('//*[@id=\"profile\"]/div[2]/table[2]/tbody/tr[3]/td[2]/span[2]')[0]\n",
    "        sheet.write(row,index+5,np_des.text)\n",
    "\n",
    "        # 净资产收益率\n",
    "        roe = e_2.xpath('//*[@id=\"profile\"]/div[2]/table[2]/tbody/tr[4]/td[3]/span[2]')[0]\n",
    "        sheet.write(row,index+6,roe.text)\n",
    "        \n",
    "        #毛利率\n",
    "        gpr = e_2.xpath('//*[@id=\"profile\"]/div[2]/table[2]/tbody/tr[4]/td[2]/span[2]')[0]\n",
    "        sheet.write(row,index+7,gpr.text)\n",
    "        \n",
    "        #每股净资产\n",
    "        nvps = e_2.xpath('//*[@id=\"profile\"]/div[2]/table[2]/tbody/tr[4]/td[1]/span[2]')[0]\n",
    "        sheet.write(row,index+8,nvps.text)\n",
    "        #股本\n",
    "        cs = e_2.xpath('//*[@id=\"profile\"]/div[2]/table[2]/tbody/tr[2]/td[4]/span[2]/text()')[0]\n",
    "        sheet.write(row,index+9,str(cs))\n",
    "        #类型\n",
    "        sst = e_2.xpath('//*[@id=\"profile\"]/div[2]/table[2]/tbody/tr[1]/td[4]/span[2]')[0]\n",
    "        sheet.write(row,index+10,sst.text)\n",
    "        \n",
    "        #财务分析\n",
    "        fa_text = ''\n",
    "        fa = e_2.xpath('//*[@id=\"profile\"]/div[2]/table[1]/tbody/tr[2]/td[2]/div[2]')\n",
    "        if len(fa) > 0:\n",
    "            for sub_fa in fa[0].getchildren():\n",
    "                fa_text = fa_text+(sub_fa.text+',')\n",
    "            sheet.write(row,index+11,fa_text)\n",
    "            \n",
    "    except ConnectionResetError:\n",
    "        print(code)\n",
    "def printProgress(content):\n",
    "    sys.stdout.write(\"\\r\" +content)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在获取：上证A股...\n",
      "第77页-第15条..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-18-2601288fea94>\", line 97, in getStockDataByType\n",
      "    company = browser.find_element_by_xpath('//*[@id=\"table_wrapper-table\"]/tbody/tr['+str(j+1)+']/td[3]/a')\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 394, in find_element_by_xpath\n",
      "    return self.find_element(by=By.XPATH, value=xpath)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 978, in find_element\n",
      "    'value': value})['value']\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"table_wrapper-table\"]/tbody/tr[16]/td[3]/a\"}\n",
      "  (Session info: chrome=75.0.3770.80)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = 'E:/wangtao/PythonWorkSpace/SpiderSpace/Stock_Companies/data/'\n",
    "# dir_path = 'D:/wt/PythonWorkSpace/DataAnalysis/Stock_Companies/data/'\n",
    "\n",
    "# getStockDataByType(\"沪市A股\")\n",
    "# workbook.save(dir_path+'上市公司沪市.xls')\n",
    "\n",
    "# getStockDataByType(\"深市A股\")\n",
    "# workbook.save(dir_path+'上市公司深市.xls')\n",
    "\n",
    "# getStockDataByType(\"中小板\")\n",
    "# workbook.save(dir_path+'上市公司中小板.xls')\n",
    "\n",
    "# getStockDataByType(\"创业板\")\n",
    "# workbook.save(dir_path+'上市公司创业板.xls')\n",
    "\n",
    "# getStockDataByType('创业板')\n",
    "# workbook.save(dir_path+'创业板.xls')\n",
    "\n",
    "# getStockDataByType('沪深A股')\n",
    "# workbook.save(dir_path+'沪深A股.xls')\n",
    "\n",
    "getStockDataByType('上证A股')\n",
    "workbook.save(dir_path+'上证A股.xls')\n",
    "\n",
    "# getStockDataByType('深证A股')\n",
    "# workbook.save(dir_path+'深证A股.xls')\n",
    "\n",
    "# getIndexStockByType('上证50')\n",
    "# workbook.save(dir_path+'上证50.xls')\n",
    "\n",
    "# getIndexStockByType('沪深300')\n",
    "# workbook.save(dir_path+'沪深300.xls')\n",
    "\n",
    "# getIndexStockByType('中证500')\n",
    "# workbook.save(dir_path+'中证500.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headers = {\"user-agent\":\"PostmanRuntime/7.13.0\"}\n",
    "# url = 'http://basic.10jqka.com.cn/002757/company.html'\n",
    "url = 'http://quote.eastmoney.com/center/gridlist.html#hs_a_board'\n",
    "response = requests.get(url,headers = headers)\n",
    "response.encoding = response.apparent_encoding\n",
    "# response.encoding = 'gbk'\n",
    "\n",
    "# response.apparent_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = etree.HTML(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = e.xpath('//*[@id=\"detail\"]/div[2]/table/tbody/tr[2]/td[2]/span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'机械设备 — 专用设备'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "element = browser.find_element_by_xpath('//*[@id=\"table_wrapper-table\"]/tbody/tr[1]/td[6]/span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'44.00%'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
